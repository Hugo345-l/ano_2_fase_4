# CardioIA - Fase 4: Lista de Tarefas Detalhadas

## üìÇ Informa√ß√µes do Projeto
**Reposit√≥rio:** `C:\Users\gugue\Documents\projetos_fiap\ano_2_fase_4\`  
**Status:** üöß Em Desenvolvimento  
**√öltima Atualiza√ß√£o:** Dezembro 2024

---

## üìã Como Usar Este Documento

- [ ] = Tarefa pendente
- [x] = Tarefa conclu√≠da
- üî¥ = Bloqueador / Aten√ß√£o necess√°ria
- üü° = Em progresso
- üü¢ = Conclu√≠do e validado

**Regra de Ouro:** ‚úÖ S√≥ marque como conclu√≠da ap√≥s validar o checkpoint correspondente!

---

## üéØ ETAPA 1: Explora√ß√£o e Compreens√£o dos Dados

### Objetivo
Entender a estrutura, qualidade e distribui√ß√£o do dataset antes de qualquer processamento.

### Tarefas

#### 1.1 Configura√ß√£o Inicial do Ambiente
- [x] Criar estrutura de pastas do projeto
  - [x] `notebooks/`
  - [x] `models/`
  - [x] `reports/`
  - [x] `results/`
- [x] Verificar que o dataset est√° em `dataset/` com subpastas train/test/val
  - ‚úÖ TRAIN: 5216 imagens (1341 NORMAL, 3875 PNEUMONIA)
  - ‚úÖ TEST: 624 imagens (234 NORMAL, 390 PNEUMONIA)
  - ‚úÖ VAL: 16 imagens (8 NORMAL, 8 PNEUMONIA)
  - ‚ö†Ô∏è Dataset desbalanceado (ratio 2.89:1) - usar class_weight
- [x] Criar notebook `cardioai_cnn_analysis.ipynb` em `notebooks/`
- [x] Instalar depend√™ncias necess√°rias:
  ```bash
  pip install -r requirements.txt
  ```
  - ‚úÖ TensorFlow 2.19.0, Keras 3.9.2
  - ‚úÖ Pillow, OpenCV, NumPy, Pandas
  - ‚úÖ Matplotlib, Seaborn
  - ‚úÖ Scikit-learn
  - ‚úÖ Jupyter, IPywidgets
  - ‚úÖ Tqdm

#### 1.2 An√°lise Explorat√≥ria Inicial
- [x] Importar bibliotecas b√°sicas (os, pathlib, PIL, matplotlib, numpy, pandas)
- [x] Mapear estrutura de diret√≥rios do dataset
  ```python
  # Exemplo de c√≥digo para mapear
  import os
  from pathlib import Path
  
  dataset_path = Path("../dataset")
  for subset in ['train', 'test', 'val']:
      for classe in ['NORMAL', 'PNEUMONIA']:
          path = dataset_path / subset / classe
          n_images = len(list(path.glob('*.jpeg')))
          print(f"{subset}/{classe}: {n_images} imagens")
  ```
- [x] Contar total de imagens por conjunto (train/test/val)
- [x] Contar imagens por classe (NORMAL vs PNEUMONIA)
- [x] Calcular propor√ß√£o de classes (verificar desbalanceamento)
  - ‚úÖ Propor√ß√£o PNEUMONIA/NORMAL: 2.89:1
  - ‚úÖ Class weights calculados: NORMAL=1.9439, PNEUMONIA=0.6726

#### 1.3 An√°lise Visual das Imagens
- [x] Carregar 5-10 imagens de exemplo de cada classe
- [x] Criar visualiza√ß√£o em grid das imagens de amostra
- [x] Verificar dimens√µes originais das imagens (altura x largura)
- [x] Verificar se todas s√£o RGB (3 canais) ou Grayscale (1 canal)
- [x] Identificar padr√µes visuais entre NORMAL e PNEUMONIA
  - ‚úÖ NORMAL: pulm√µes limpos e claros
  - ‚úÖ PNEUMONIA: opacidades e infiltrados vis√≠veis

#### 1.4 An√°lise de Qualidade
- [x] Verificar se h√° imagens corrompidas ou ileg√≠veis (nenhuma encontrada)
- [x] Checar distribui√ß√£o de tamanhos das imagens (amostra de 100)
- [x] Identificar imagens com dimens√µes muito diferentes da m√©dia
- [x] Documentar observa√ß√µes sobre qualidade do dataset
  - ‚úÖ Dimens√µes variam: largura/altura ~1000-2000px
  - ‚úÖ Todas no formato JPEG, RGB
  - ‚úÖ Qualidade adequada para treinamento

### ‚úÖ CHECKPOINT 1 - Valida√ß√£o
Antes de avan√ßar, confirme:
- [x] Consegue carregar imagens sem erros
- [x] Visualizou pelo menos 5 imagens de cada classe
- [x] Entende a distribui√ß√£o (Ex: train=5216, test=624, val=16)
- [x] Identificou dimens√µes t√≠picas (podem variar, mas geralmente ~1000-2000px)

**Entreg√°vel:** Se√ß√£o de an√°lise explorat√≥ria no notebook com visualiza√ß√µes

üü¢ **ETAPA 1 CONCLU√çDA - Dezembro 2024**

---

## üîß ETAPA 2: Pr√©-processamento e Prepara√ß√£o dos Dados

### Objetivo
Preparar o dataset para treinamento das redes neurais, garantindo formato e qualidade adequados.

### Tarefas

#### 2.1 Setup de Pr√©-processamento
- [x] Importar bibliotecas de pr√©-processamento
  ```python
  from tensorflow.keras.preprocessing.image import ImageDataGenerator
  from tensorflow.keras.preprocessing import image
  import tensorflow as tf
  ```
- [ x] Definir par√¢metros globais:
  - [ x] `IMG_HEIGHT = 224`
  - [ x] `IMG_WIDTH = 224`
  - [ x] `BATCH_SIZE = 32`
  - [x ] `CLASSES = ['NORMAL', 'PNEUMONIA']`

#### 2.2 Criar ImageDataGenerators
- [x ] Criar generator para TREINO com data augmentation:
  ```python
  train_datagen = ImageDataGenerator(
      rescale=1./255,              # Normaliza√ß√£o
      rotation_range=20,           # Rota√ß√£o aleat√≥ria
      width_shift_range=0.2,       # Deslocamento horizontal
      height_shift_range=0.2,      # Deslocamento vertical
      horizontal_flip=True,        # Flip horizontal
      zoom_range=0.2,              # Zoom aleat√≥rio
      fill_mode='nearest'          # Preencher pixels criados
  )
  ```
- [ x] Criar generator para VALIDA√á√ÉO (sem augmentation):
  ```python
  val_datagen = ImageDataGenerator(rescale=1./255)
  ```
- [x ] Criar generator para TESTE (sem augmentation):
  ```python
  test_datagen = ImageDataGenerator(rescale=1./255)
  ```

#### 2.3 Configurar Data Loaders
- [ ] Criar train_generator apontando para `dataset/train/`
- [ ] Criar validation_generator apontando para `dataset/val/`
- [ ] Criar test_generator apontando para `dataset/test/`
- [ ] Verificar que class_mode='binary' (classifica√ß√£o bin√°ria)
- [ ] Confirmar que color_mode='rgb' (3 canais)

#### 2.4 Testes de Valida√ß√£o do Pipeline
- [ ] Carregar um batch de treino e verificar shape: (32, 224, 224, 3)
- [ ] Verificar que valores est√£o entre 0-1 (normaliza√ß√£o aplicada)
- [ ] Visualizar imagens com data augmentation aplicado
- [ ] Criar compara√ß√£o lado-a-lado: original vs augmented
- [ ] Confirmar que labels est√£o corretos (0=NORMAL, 1=PNEUMONIA ou vice-versa)

#### 2.5 An√°lise de Balanceamento
- [ x] Calcular pesos de classe se houver desbalanceamento
  ```python
  from sklearn.utils.class_weight import compute_class_weight
  
  class_weights = compute_class_weight(
      'balanced',
      classes=np.unique(train_generator.classes),
      y=train_generator.classes
  )
  ```
- [ x] Documentar estrat√©gia para lidar com desbalanceamento (class weights ou oversampling)

### ‚úÖ CHECKPOINT 2 - Valida√ß√£o
Antes de avan√ßar, confirme:
- [ x] Todas as imagens foram redimensionadas para 224x224
- [x ] Valores dos pixels est√£o entre 0 e 1
- [ x] Visualizou exemplos de data augmentation
- [x ] Train/val/test est√£o separados corretamente
- [x ] Generators carregam batches sem erros

**Entreg√°vel:** Pipeline de pr√©-processamento funcional e testado

---

## üß† ETAPA 3: CNN Simples do Zero ‚úÖ CONCLU√çDA

### Objetivo
Implementar e treinar uma rede neural convolucional b√°sica criada do zero.

### Tarefas

#### 3.1 Definir Arquitetura da CNN
- [x] Importar m√≥dulos necess√°rios do Keras
  ```python
  from tensorflow.keras import layers, models
  from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
  ```
- [x] Criar modelo Sequential
- [x] Adicionar camadas conforme arquitetura:
  ```python
  model = models.Sequential([
      # Bloco 1
      layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
      layers.MaxPooling2D((2,2)),
      
      # Bloco 2
      layers.Conv2D(64, (3,3), activation='relu'),
      layers.MaxPooling2D((2,2)),
      
      # Bloco 3
      layers.Conv2D(128, (3,3), activation='relu'),
      layers.MaxPooling2D((2,2)),
      
      # Bloco 4 (opcional)
      layers.Conv2D(128, (3,3), activation='relu'),
      layers.MaxPooling2D((2,2)),
      
      # Flatten e camadas densas
      layers.Flatten(),
      layers.Dense(512, activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(1, activation='sigmoid')  # Sa√≠da bin√°ria
  ])
  ```
- [x] Visualizar resumo do modelo com `model.summary()`
- [x] Calcular n√∫mero total de par√¢metros trein√°veis

#### 3.2 Compilar Modelo
- [x] Definir otimizador: `Adam(learning_rate=0.001)`
- [x] Definir fun√ß√£o de perda: `binary_crossentropy`
- [x] Definir m√©tricas: `['accuracy']`
- [x] Compilar modelo:
  ```python
  model.compile(
      optimizer='adam',
      loss='binary_crossentropy',
      metrics=['accuracy']
  )
  ```

#### 3.3 Configurar Callbacks
- [x] Criar EarlyStopping:
  ```python
  early_stop = EarlyStopping(
      monitor='val_loss',
      patience=5,
      restore_best_weights=True
  )
  ```
- [x] Criar ModelCheckpoint:
  ```python
  checkpoint = ModelCheckpoint(
      '../models/cnn_baseline.keras',
      monitor='val_accuracy',
      save_best_only=True
  )
  ```

#### 3.4 Treinar Modelo
- [x] Definir n√∫mero de epochs (20-30)
- [x] Calcular steps_per_epoch se necess√°rio
- [x] Iniciar treinamento:
  ```python
  history = model.fit(
      train_generator,
      epochs=25,
      validation_data=validation_generator,
      callbacks=[early_stop, checkpoint],
      class_weight=class_weights  # Se calculado na Etapa 2
  )
  ```
- [x] Monitorar progresso epoch por epoch
- [x] Salvar hist√≥rico de treinamento

#### 3.5 Visualizar Resultados do Treinamento
- [x] Plotar Loss (treino vs valida√ß√£o):
  ```python
  plt.plot(history.history['loss'], label='Train Loss')
  plt.plot(history.history['val_loss'], label='Val Loss')
  plt.legend()
  ```
- [x] Plotar Accuracy (treino vs valida√ß√£o)
- [x] Identificar se houve overfitting (treino >> valida√ß√£o)
- [x] Identificar se houve underfitting (ambos com accuracy baixa)
- [x] Salvar gr√°ficos em `results/cnn_baseline_training.png`

#### 3.6 Avaliar no Conjunto de Teste
- [x] Carregar melhor modelo salvo
- [x] Avaliar no test_generator:
  ```python
  test_loss, test_accuracy = model.evaluate(test_generator)
  print(f"Test Accuracy: {test_accuracy:.4f}")
  ```
- [x] Gerar predi√ß√µes para todo conjunto de teste
- [x] Documentar acur√°cia final no teste

#### 3.7 Teste de Predi√ß√£o
- [x] Carregar uma imagem nova n√£o vista
- [x] Pr√©-processar (resize + normalize)
- [x] Fazer predi√ß√£o:
  ```python
  prediction = model.predict(img_array)
  print("NORMAL" if prediction[0][0] < 0.5 else "PNEUMONIA")
  ```
- [x] Visualizar imagem + predi√ß√£o

### ‚úÖ CHECKPOINT 3 - Valida√ß√£o
Antes de avan√ßar, confirme:
- [x] Modelo compila sem erros
- [x] Treinamento executou e mostrou progresso
- [x] Gr√°ficos de loss/accuracy foram gerados
- [x] Acur√°cia de valida√ß√£o > 60% (baseline m√≠nimo)
- [x] Modelo faz predi√ß√µes em imagens novas

**Entreg√°vel:** CNN b√°sica treinada com m√©tricas documentadas

### üéØ RESULTADOS FINAIS - ETAPA 3 ‚úÖ CONCLU√çDA

**Status:** ‚úÖ COMPLETADA - Dezembro 2024

**Treinamento:**
- Plataforma: Kaggle (GPU Tesla T4)
- Epochs executados: 12 (early stopping)
- Melhor modelo: Epoch 5
- Tempo total: ~21 minutos

**M√©tricas no Conjunto de Teste:**
- ‚úÖ **Test Accuracy:** 88.46% (Meta: >70% SUPERADA!)
- ‚úÖ **Test Recall:** 96.15% (Meta: >85% SUPERADA!)
- **Test Precision:** 86.81%
- **Test AUC:** 0.9437
- **Test Loss:** 0.4529

**Matriz de Confus√£o:**
- True Negatives (TN): 177
- False Positives (FP): 57 (alarmes falsos - aceit√°vel)
- False Negatives (FN): 15 (casos perdidos - apenas 3.85%!)
- True Positives (TP): 375

**An√°lise Cl√≠nica:**
- ‚≠ê **Recall de 96.15% √© EXCEPCIONAL** para detec√ß√£o de PNEUMONIA
- Apenas 15 de 390 casos perdidos (3.85%)
- Trade-off ideal: alta sensibilidade + boa especificidade
- Modelo prioriza n√£o perder casos graves (comportamento correto!)

**Arquivos Salvos:**
- ‚úÖ `models/cnn_baseline_best.keras` - Melhor modelo
- ‚úÖ `results/cnn_baseline_confusion_matrix.png` - Matriz de confus√£o
- ‚úÖ `results/cnn_baseline_metrics_detailed.png` - Gr√°ficos de m√©tricas

üü¢ **ETAPA 3 VALIDADA E CONCLU√çDA COM SUCESSO!**

---

## üîÑ ETAPA 4: Transfer Learning com Modelo Pr√©-treinado ‚úÖ CONCLU√çDA

### Objetivo
Implementar Transfer Learning usando modelo pr√©-treinado (VGG16 ou ResNet50) para melhorar resultados.

### Tarefas

#### 4.1 Escolher Modelo Base
- [x] Decidir entre VGG16 (mais simples) ou ResNet50 (melhor performance)
  - ‚úÖ **Escolhido: VGG16** (melhor equil√≠brio simplicidade/performance)
- [x] Importar modelo escolhido:
  ```python
  from tensorflow.keras.applications import VGG16
  ```

#### 4.2 Carregar Modelo Pr√©-treinado
- [x] Carregar modelo sem camada de classifica√ß√£o (include_top=False):
  ```python
  base_model = VGG16(
      weights='imagenet',
      include_top=False,
      input_shape=(224, 224, 3)
  )
  ```
- [x] Congelar camadas do modelo base:
  ```python
  base_model.trainable = False
  ```
  - ‚úÖ 14.714.688 par√¢metros n√£o-trein√°veis (VGG16 congelado)
- [x] Verificar resumo do modelo base

#### 4.3 Adicionar Camadas de Classifica√ß√£o Customizadas
- [x] Criar modelo completo:
  ```python
  model_tl = models.Sequential([
      base_model,
      layers.GlobalAveragePooling2D(),
      layers.Dense(256, activation='relu'),
      layers.BatchNormalization(),
      layers.Dropout(0.5),
      layers.Dense(128, activation='relu'),
      layers.Dropout(0.3),
      layers.Dense(1, activation='sigmoid')
  ])
  ```
- [x] Verificar que apenas camadas novas s√£o trein√°veis
  - ‚úÖ 164.865 par√¢metros trein√°veis (apenas camadas customizadas)
- [x] Visualizar model.summary() e confirmar par√¢metros trein√°veis vs n√£o-trein√°veis

#### 4.4 Compilar Modelo Transfer Learning
- [x] Compilar com mesmos par√¢metros da CNN b√°sica:
  ```python
  model_tl.compile(
      optimizer='adam',
      loss='binary_crossentropy',
      metrics=['accuracy', 'precision', 'recall', 'auc']
  )
  ```

#### 4.5 Configurar Callbacks
- [x] Criar EarlyStopping (patience=5)
- [x] Criar ModelCheckpoint para salvar em `models/transfer_learning_vgg16_best.keras`
- [x] Criar ReduceLROnPlateau (factor=0.5, patience=3)

#### 4.6 Treinar Modelo Transfer Learning
- [x] Treinar com 25 epochs (early stopping ativado):
  ```python
  history_tl = model_tl.fit(
      train_generator,
      epochs=25,
      validation_data=validation_generator,
      callbacks=[early_stop, checkpoint, reduce_lr],
      class_weight=class_weights
  )
  ```
- [x] Monitorar converg√™ncia (convergiu mais r√°pido que CNN baseline)
  - ‚úÖ Parou no epoch 21 (early stopping)
  - ‚úÖ Melhor modelo: epoch 9 (val_accuracy: 93.75%)
  - ‚úÖ Learning rate reduzido 3x durante o treino

#### 4.7 (Opcional) Fine-tuning
- [ ] Descongelar √∫ltimas camadas do base_model (N√ÉO REALIZADO)
  - ‚ö†Ô∏è N√£o foi necess√°rio - resultados j√° satisfat√≥rios

#### 4.8 Visualizar e Avaliar
- [x] Plotar gr√°ficos de Loss e Accuracy
- [x] Avaliar no conjunto de teste
- [x] Comparar resultados com CNN b√°sica
- [x] Documentar melhoria de performance
  - ‚úÖ Gr√°ficos de compara√ß√£o gerados
  - ‚úÖ Matrizes de confus√£o lado a lado
  - ‚úÖ An√°lise detalhada documentada

### ‚úÖ CHECKPOINT 4 - Valida√ß√£o
Antes de avan√ßar, confirme:
- [x] Modelo pr√©-treinado carregou corretamente
- [x] Camadas base est√£o congeladas (trainable=False)
- [x] Treinamento convergiu mais r√°pido que CNN b√°sica
- [x] Acur√°cia de valida√ß√£o > 80% (93.75% no melhor epoch)
- [x] Transfer Learning comparado com CNN b√°sica

**Entreg√°vel:** Modelo de Transfer Learning treinado com comparativo

### üéØ RESULTADOS FINAIS - ETAPA 4 ‚úÖ CONCLU√çDA

**Status:** ‚úÖ COMPLETADA - Dezembro 2024

**Treinamento:**
- Plataforma: Kaggle (GPU Tesla P100)
- Epochs executados: 21 (early stopping no epoch 21)
- Melhor modelo: Epoch 9 (val_accuracy: 93.75%)
- Tempo total: ~32 minutos

**M√©tricas no Conjunto de Teste:**
- ‚úÖ **Test Accuracy:** 90.71% (Meta: >85% SUPERADA!)
- **Test Recall:** 91.79% (Bom, mas menor que CNN Baseline)
- ‚úÖ **Test Precision:** 93.23% (Excelente!)
- ‚úÖ **Test AUC:** 0.9581
- **Test Loss:** 0.3264

**Matriz de Confus√£o:**
- True Negatives (TN): 208
- False Positives (FP): 26 (alarmes falsos)
- False Negatives (FN): 32 (casos perdidos - 8.21%)
- True Positives (TP): 358

**Compara√ß√£o: CNN Baseline vs Transfer Learning VGG16**

| M√©trica | CNN Baseline | Transfer Learning | Diferen√ßa |
|---------|--------------|-------------------|-----------|
| **Accuracy** | 88.46% | **90.71%** ‚úÖ | +2.25% |
| **Precision** | 86.81% | **93.23%** ‚úÖ | +7.39% |
| **Recall** | **96.15%** ‚úÖ | 91.79% | -4.36% |
| **AUC** | 94.37% | **95.81%** ‚úÖ | +1.52% |
| **False Negatives** | **15** ‚úÖ | 32 | +17 casos |

**An√°lise Cr√≠tica:**

‚úÖ **Vantagens do Transfer Learning:**
- **Maior acur√°cia geral** (+2.25%)
- **Maior precis√£o** (+7.39%) - Menos alarmes falsos
- **Melhor AUC** (+1.52%) - Melhor separa√ß√£o de classes
- **Converg√™ncia mais r√°pida** - Features pr√©-treinadas

‚ö†Ô∏è **PONTO CR√çTICO - Contexto M√©dico:**
- **CNN Baseline √© SUPERIOR para detec√ß√£o de PNEUMONIA!** üè•
- CNN Baseline tem **Recall de 96.15%** vs Transfer Learning **91.79%**
- CNN Baseline perde **apenas 15 casos** vs Transfer Learning **32 casos**
- **Em medicina, Recall √© CR√çTICO** - perder casos graves pode ser fatal

**Recomenda√ß√£o Final:**
- üéØ **Para aplica√ß√£o m√©dica:** Use **CNN Baseline** (melhor recall)
- üìä **Para aplica√ß√£o geral:** Transfer Learning tem melhor precis√£o
- üîß **Pr√≥ximos passos:** Ensemble (combinar ambos) ou fine-tuning do VGG16

**Arquivos Salvos:**
- ‚úÖ `models/transfer_learning_vgg16_best.keras` - Melhor modelo
- ‚úÖ `results/transfer_learning_confusion_matrix.png` - Matriz de confus√£o
- ‚úÖ `results/comparison_metrics.png` - Gr√°fico comparativo de m√©tricas
- ‚úÖ `results/comparison_confusion_matrices.png` - Matrizes lado a lado

üü¢ **ETAPA 4 VALIDADA E CONCLU√çDA COM SUCESSO!**

---

## üìä ETAPA 5: Avalia√ß√£o Completa dos Modelos ‚úÖ CONCLU√çDA

### Objetivo
Avaliar ambos os modelos com m√©tricas detalhadas e comparar performance.

### Tarefas

#### 5.1 Setup de Avalia√ß√£o
- [x] Importar bibliotecas de m√©tricas:
  ```python
  from sklearn.metrics import (
      classification_report,
      confusion_matrix,
      accuracy_score,
      precision_score,
      recall_score,
      f1_score
  )
  ```
  - ‚úÖ Implementado na Etapa 4 (c√©lulas 8 e 9)

#### 5.2 Gerar Predi√ß√µes
- [x] Carregar modelos salvos (CNN baseline e Transfer Learning)
- [x] Gerar predi√ß√µes para conjunto de teste:
  ```python
  # CNN Baseline - j√° gerado na Etapa 3
  # Transfer Learning - gerado na Etapa 4, c√©lula 8
  y_pred_proba_tl = model_tl_best.predict(test_generator)
  y_pred_classes_tl = (y_pred_proba_tl > 0.5).astype(int).flatten()
  ```
- [x] Obter labels verdadeiros do test_generator

#### 5.3 Calcular M√©tricas - CNN Baseline
- [x] Calcular Acur√°cia (88.46%)
- [x] Calcular Precis√£o (86.81%)
- [x] Calcular Recall (96.15%)
- [x] Calcular F1-Score
- [x] Gerar relat√≥rio de classifica√ß√£o completo
  - ‚úÖ Realizado na Etapa 3

#### 5.4 Calcular M√©tricas - Transfer Learning
- [x] Calcular todas as mesmas m√©tricas para modelo TL
  - Accuracy: 90.71%
  - Precision: 93.23%
  - Recall: 91.79%
  - AUC: 95.81%
- [x] Gerar relat√≥rio de classifica√ß√£o

#### 5.5 Criar Matrizes de Confus√£o
- [x] Gerar matriz de confus√£o para CNN baseline
- [x] Gerar matriz de confus√£o para Transfer Learning
- [x] Visualizar ambas com heatmap lado a lado
  - ‚úÖ `results/comparison_confusion_matrices.png` criado na c√©lula 9

#### 5.6 An√°lise Comparativa
- [x] Criar tabela comparativa de m√©tricas com DataFrame pandas
- [x] Plotar gr√°fico de barras comparativo
  - ‚úÖ `results/comparison_metrics.png` criado
- [x] An√°lise de melhoria percentual calculada

#### 5.7 An√°lise de Erros
- [x] Identificar Falsos Positivos e Falsos Negativos
  - CNN Baseline: 15 FN, 57 FP
  - Transfer Learning: 32 FN, 26 FP
- [x] An√°lise quantitativa dos erros
- [ ] Visualizar exemplos de erros (OPCIONAL - n√£o cr√≠tico)

#### 5.8 Interpreta√ß√£o M√©dica
- [x] Discutir import√¢ncia do Recall no contexto m√©dico
  - ‚úÖ "CNN Baseline √© SUPERIOR para detec√ß√£o de PNEUMONIA" documentado
- [x] Analisar custo de FN vs FP
  - üè• FN mais cr√≠tico que FP em contexto m√©dico
- [x] Documentar qual m√©trica priorizar para uso m√©dico
  - üéØ Recall √© CR√çTICO para medicina

### ‚úÖ CHECKPOINT 5 - Valida√ß√£o
Antes de avan√ßar, confirme:
- [x] Todas as m√©tricas calculadas para ambos os modelos
- [x] Matrizes de confus√£o leg√≠veis e corretas
- [x] Compara√ß√£o clara entre os dois modelos
- [x] An√°lise quantitativa de erros (FN e FP)
- [x] An√°lise cr√≠tica dos resultados documentada

**Entreg√°vel:** Relat√≥rio de m√©tricas e an√°lise comparativa

### üéØ RESULTADOS FINAIS - ETAPA 5 ‚úÖ CONCLU√çDA

**Status:** ‚úÖ COMPLETADA - Dezembro 2024 (Integrada na Etapa 4)

**An√°lise Comparativa Completa:**

| M√©trica | CNN Baseline | Transfer Learning | Melhor Modelo |
|---------|--------------|-------------------|---------------|
| **Accuracy** | 88.46% | 90.71% | Transfer Learning |
| **Precision** | 86.81% | 93.23% | Transfer Learning |
| **Recall** | 96.15% | 91.79% | **CNN Baseline** ‚úÖ |
| **AUC** | 94.37% | 95.81% | Transfer Learning |
| **False Negatives** | 15 | 32 | **CNN Baseline** ‚úÖ |

**Conclus√£o Cr√≠tica:**
- ‚úÖ Transfer Learning: Melhor acur√°cia geral e precis√£o
- üè• **CNN Baseline: RECOMENDADO para uso m√©dico** (Recall 96.15%)
- üî¥ Perder 32 casos (TL) vs 15 casos (CNN) pode ser fatal em medicina

**Arquivos Gerados:**
- ‚úÖ `results/comparison_metrics.png` - Gr√°fico comparativo
- ‚úÖ `results/comparison_confusion_matrices.png` - Matrizes lado a lado
- ‚úÖ `results/transfer_learning_confusion_matrix.png` - Matriz TL
- ‚úÖ `results/cnn_baseline_confusion_matrix.png` - Matriz CNN

üü¢ **ETAPA 5 VALIDADA E CONCLU√çDA COM SUCESSO!**

---

## üíª ETAPA 6: Prot√≥tipo de Apresenta√ß√£o (Notebook Interativo)

### Objetivo
Organizar o notebook final com apresenta√ß√£o clara e interativa dos resultados.

### Tarefas

#### 6.1 Estruturar Notebook
- [ ] Reorganizar c√©lulas em se√ß√µes claras:
  1. [ ] **Introdu√ß√£o e Contexto** (Markdown)
  2. [ ] **Importa√ß√£o de Bibliotecas**
  3. [ ] **Configura√ß√µes Globais** (caminhos, par√¢metros)
  4. [ ] **Explora√ß√£o dos Dados** (Etapa 1)
  5. [ ] **Pr√©-processamento** (Etapa 2)
  6. [ ] **Modelo 1: CNN do Zero** (Etapa 3)
  7. [ ] **Modelo 2: Transfer Learning** (Etapa 4)
  8. [ ] **Compara√ß√£o de Resultados** (Etapa 5)
  9. [ ] **Demo Interativa**
  10. [ ] **Conclus√µes e Pr√≥ximos Passos**

#### 6.2 Adicionar Textos Explicativos
- [ ] Escrever introdu√ß√£o explicando o problema e objetivo
- [ ] Adicionar descri√ß√£o do dataset
- [ ] Explicar cada escolha t√©cnica (por que 224x224? por que VGG16?)
- [ ] Comentar cada gr√°fico e visualiza√ß√£o
- [ ] Interpretar resultados das m√©tricas

#### 6.3 Criar Se√ß√£o de Demo Interativa
- [ ] Criar fun√ß√£o de predi√ß√£o completa:
  ```python
  def predict_image(image_path, model):
      img = image.load_img(image_path, target_size=(224, 224))
      img_array = image.img_to_array(img) / 255.0
      img_array = np.expand_dims(img_array, axis=0)
      
      prediction = model.predict(img_array)[0][0]
      classe = "PNEUMONIA" if prediction > 0.5 else "NORMAL"
      confianca = prediction if prediction > 0.5 else (1 - prediction)
      
      plt.imshow(img)
      plt.title(f"Predi√ß√£o: {classe} ({confianca:.2%} confian√ßa)")
      plt.axis('off')
      plt.show()
      
      return classe, confianca
  ```
- [ ] Testar com 5-10 imagens novas
- [ ] Criar visualiza√ß√£o lado-a-lado com ambos os modelos

#### 6.4 Adicionar Visualiza√ß√µes Finais
- [ ] Criar resumo visual dos melhores resultados
- [ ] Adicionar compara√ß√£o final em formato de infogr√°fico
- [ ] Incluir interpreta√ß√£o dos resultados

#### 6.5 Polimento e Qualidade
- [ ] Garantir que todas as c√©lulas executam sem erros
- [ ] Limpar c√©lulas de teste/debug
- [ ] Adicionar numera√ß√£o de se√ß√µes
- [ ] Revisar ortografia e gram√°tica dos textos
- [ ] Garantir que gr√°ficos t√™m t√≠tulos e legendas claras
- [ ] Adicionar cores e formata√ß√£o para melhorar legibilidade

#### 6.6 Teste de Reprodutibilidade
- [ ] Reiniciar kernel e executar notebook do in√≠cio ao fim
- [ ] Verificar que n√£o h√° erros de execu√ß√£o
- [ ] Confirmar que resultados s√£o consistentes
- [ ] Documentar tempo aproximado de execu√ß√£o de cada se√ß√£o

### ‚úÖ CHECKPOINT 6 - Valida√ß√£o Final
Antes de avan√ßar, confirme:
- [ ] Notebook executa do in√≠cio ao fim sem erros
- [ ] Todas as se√ß√µes t√™m t√≠tulos e explica√ß√µes claras
- [ ] Gr√°ficos e visualiza√ß√µes est√£o leg√≠veis
- [ ] Fun√ß√£o de predi√ß√£o em imagens novas funciona
- [ ] Resultados finais est√£o destacados e bem apresentados

**Entreg√°vel:** Notebook interativo finalizado

---

## üìù ETAPA 7: Documenta√ß√£o e Relat√≥rio Final

### Objetivo
Criar relat√≥rio t√©cnico conciso documentando todo o processo e resultados.

### Tarefas

#### 7.1 Estruturar Relat√≥rio (1-2 p√°ginas)
- [ ] Criar documento em formato PDF ou Word
- [ ] Definir estrutura:
  1. Introdu√ß√£o
  2. Metodologia
  3. Resultados
  4. Conclus√µes

#### 7.2 Se√ß√£o 1: Introdu√ß√£o
- [ ] Contextualizar o projeto CardioIA
- [ ] Apresentar objetivo do prot√≥tipo
- [ ] Mencionar dataset utilizado (Chest X-Ray Pneumonia)
- [ ] Descrever brevemente o problema (classifica√ß√£o NORMAL vs PNEUMONIA)

#### 7.3 Se√ß√£o 2: Metodologia
- [ ] **Dataset:**
  - [ ] Descrever fonte (Kaggle)
  - [ ] Quantidade de imagens (train/val/test)
  - [ ] Classes e distribui√ß√£o
  
- [ ] **Pipeline de Pr√©-processamento:**
  - [ ] Redimensionamento para 224x224
  - [ ] Normaliza√ß√£o de pixels (0-1)
  - [ ] Data augmentation (rota√ß√£o, zoom, flip)
  - [ ] Justificar escolhas
  
- [ ] **Arquiteturas Implementadas:**
  - [ ] CNN Baseline:
    - [ ] Descrever arquitetura (blocos Conv2D + MaxPool + Dense)
    - [ ] N√∫mero de par√¢metros
    - [ ] Hiperpar√¢metros (batch_size, learning_rate, epochs)
  - [ ] Transfer Learning:
    - [ ] Modelo base escolhido (VGG16 ou ResNet50)
    - [ ] Justificar escolha
    - [ ] Camadas customizadas adicionadas
    - [ ] Estrat√©gia de fine-tuning (se aplicado)

#### 7.4 Se√ß√£o 3: Resultados
- [ ] Criar tabela comparativa de m√©tricas:
  ```
  | Modelo              | Acur√°cia | Precis√£o | Recall | F1-Score |
  |---------------------|----------|----------|--------|----------|
  | CNN Baseline        | XX.X%    | XX.X%    | XX.X%  | XX.X%    |
  | Transfer Learning   | YY.Y%    | YY.Y%    | YY.Y%  | YY.Y%    |
  ```
- [ ] Incluir gr√°ficos principais:
  - [ ] Matriz de confus√£o (ambos os modelos)
  - [ ] Compara√ß√£o visual de m√©tricas
  - [ ] Curvas de Loss/Accuracy (se houver espa√ßo)
  
- [ ] An√°lise dos Resultados:
  - [ ] Qual modelo teve melhor performance?
  - [ ] Diferen√ßa significativa entre os modelos?
  - [ ] Modelo atendeu expectativas (>80% acur√°cia)?
  - [ ] An√°lise de Recall no contexto m√©dico (casos perdidos)

#### 7.5 Se√ß√£o 4: Conclus√µes
- [ ] Resumir principais achados
- [ ] Indicar qual modelo √© mais eficaz e por qu√™
- [ ] Discutir limita√ß√µes encontradas:
  - [ ] Desbalanceamento de classes?
  - [ ] Overfitting/Underfitting?
  - [ ] Tamanho do conjunto de valida√ß√£o?
  - [ ] Qualidade das imagens?
  
- [ ] Propor pr√≥ximos passos:
  - [ ] Coletar mais dados
  - [ ] Testar outras arquiteturas (ResNet, EfficientNet)
  - [ ] Implementar t√©cnicas de interpretabilidade (Grad-CAM)
  - [ ] Valida√ß√£o com especialistas m√©dicos
  - [ ] Deploy em ambiente de produ√ß√£o

#### 7.6 Formata√ß√£o e Revis√£o
- [ ] Garantir que relat√≥rio tem 1-2 p√°ginas (m√°ximo)
- [ ] Adicionar cabe√ßalho com:
  - [ ] T√≠tulo do projeto
  - [ ] Seu nome
  - [ ] Data
  - [ ] Institui√ß√£o (FIAP)
- [ ] Numerar se√ß√µes
- [ ] Adicionar legendas em todas as tabelas e figuras
- [ ] Revisar ortografia e gram√°tica
- [ ] Garantir formata√ß√£o consistente (fonte, espa√ßamento)
- [ ] Exportar para PDF

#### 7.7 Salvar e Organizar
- [ ] Salvar relat√≥rio em `reports/relatorio_tecnico.pdf`
- [ ] Verificar que todos os gr√°ficos est√£o salvos em `results/`
- [ ] Criar README.md na raiz do projeto com instru√ß√µes de uso
- [ ] Organizar todos os arquivos finais

### ‚úÖ CHECKPOINT 7 - Entrega Final
Antes de considerar conclu√≠do, confirme:
- [ ] Relat√≥rio tem 1-2 p√°ginas
- [ ] Todas as escolhas t√©cnicas est√£o justificadas
- [ ] Resultados apresentados de forma clara
- [ ] Documento bem formatado e sem erros
- [ ] Todos os entreg√°veis est√£o organizados

**Entreg√°vel Final:** Relat√≥rio t√©cnico completo

---

## üì¶ CHECKLIST FINAL DE ENTREGA

### Estrutura de Arquivos
```
C:\Users\gugue\Documents\projetos_fiap\ano_2_fase_4\
‚îú‚îÄ‚îÄ PLANNING.md ‚úÖ
‚îú‚îÄ‚îÄ TASKS.md ‚úÖ
‚îú‚îÄ‚îÄ dataset\
‚îÇ   ‚îú‚îÄ‚îÄ train\
‚îÇ   ‚îú‚îÄ‚îÄ test\
‚îÇ   ‚îî‚îÄ‚îÄ val\
‚îú‚îÄ‚îÄ notebooks\
‚îÇ   ‚îî‚îÄ‚îÄ cardioai_cnn_analysis.ipynb ‚¨ú
‚îú‚îÄ‚îÄ models\
‚îÇ   ‚îú‚îÄ‚îÄ cnn_baseline.keras ‚¨ú
‚îÇ   ‚îî‚îÄ‚îÄ transfer_learning_vgg16.keras ‚¨ú
‚îú‚îÄ‚îÄ reports\
‚îÇ   ‚îî‚îÄ‚îÄ relatorio_tecnico.pdf ‚¨ú
‚îî‚îÄ‚îÄ results\
    ‚îú‚îÄ‚îÄ metricas_comparacao.png ‚¨ú
    ‚îî‚îÄ‚îÄ matriz_confusao.png ‚¨ú
```

### Entreg√°veis Obrigat√≥rios
- [ ] ‚úÖ Notebook Python completo e execut√°vel
  - [ ] C√≥digo de pr√©-processamento
  - [ ] CNN do zero implementada
  - [ ] Transfer Learning implementado
  - [ ] Todas as m√©tricas calculadas
  - [ ] Demo de predi√ß√£o funcional
  
- [ ] ‚úÖ Relat√≥rio T√©cnico (1-2 p√°ginas)
  - [ ] Metodologia documentada
  - [ ] Justificativas t√©cnicas
  - [ ] Resultados apresentados
  - [ ] Conclus√µes claras
  
- [ ] ‚úÖ Prints/Gr√°ficos de M√©tricas
  - [ ] Acur√°cia, Precis√£o, Recall, F1-Score
  - [ ] Matrizes de confus√£o
  - [ ] Gr√°ficos de Loss e Accuracy

### Crit√©rios de Avalia√ß√£o (10 pontos)
- [ ] Pipeline de pr√©-processamento implementado (3 pontos)
- [ ] CNN do zero treinada e avaliada (2 pontos)
- [ ] Transfer Learning implementado (2 pontos)
- [ ] Prot√≥tipo de apresenta√ß√£o (notebook) (2 pontos)
- [ ] Documenta√ß√£o clara (1 ponto)

---

## üéØ Meta de Qualidade

### Resultados Esperados
- **CNN Baseline:** Acur√°cia > 70% no teste
- **Transfer Learning:** Acur√°cia > 85% no teste
- **Recall (PNEUMONIA):** > 85% (cr√≠tico para √°rea m√©dica!)

### Sinais de Sucesso
‚úÖ Pipeline de dados funciona sem erros  
‚úÖ Modelos convergem durante treinamento  
‚úÖ Transfer Learning supera CNN baseline  
‚úÖ Notebook executa do in√≠cio ao fim  
‚úÖ Relat√≥rio est√° completo e bem escrito  

---

**Boa sorte, Hugo! üöÄ**

**√öltima Atualiza√ß√£o:** Dezembro 2024  
**Vers√£o:** 1.0
